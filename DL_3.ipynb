{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee3090c4db6847fe93a9e85db6592a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6a73b5be0334b8fbec17a336b1c537b",
              "IPY_MODEL_a91821799b3e4b8fbb0e68ca25fd010b",
              "IPY_MODEL_7661278b6b884818b77f7e01b27332f1"
            ],
            "layout": "IPY_MODEL_9e753b81d7204a12bf4fa5534c67d241"
          }
        },
        "f6a73b5be0334b8fbec17a336b1c537b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76e88cfc66cc44fbb47f1e4f3e447742",
            "placeholder": "​",
            "style": "IPY_MODEL_7ae4462e26c0427182cb25542b2b404b",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "a91821799b3e4b8fbb0e68ca25fd010b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_031aa630dd154c8cb5b72f4d8d9422a0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_187b1cc830bf4072893d97071b388291",
            "value": 2
          }
        },
        "7661278b6b884818b77f7e01b27332f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a57123e6af246de8744e8944715acff",
            "placeholder": "​",
            "style": "IPY_MODEL_e210af776b11499cb624cd8d62307488",
            "value": " 2/2 [00:01&lt;00:00,  1.23it/s]"
          }
        },
        "9e753b81d7204a12bf4fa5534c67d241": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "76e88cfc66cc44fbb47f1e4f3e447742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ae4462e26c0427182cb25542b2b404b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "031aa630dd154c8cb5b72f4d8d9422a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "187b1cc830bf4072893d97071b388291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a57123e6af246de8744e8944715acff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e210af776b11499cb624cd8d62307488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b5f2c2b977c41bc8ed0cfa5654766f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3034ff8d2536450b993967151cb793cd",
              "IPY_MODEL_92c90646fd5f4294ad860bac64ef2695",
              "IPY_MODEL_a82550e9015f4ba1a655cd8a865aac70"
            ],
            "layout": "IPY_MODEL_d50dd100a48e483cb152fe37957456c6"
          }
        },
        "3034ff8d2536450b993967151cb793cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99f700ce24c44bf68b786bb8bd38d367",
            "placeholder": "​",
            "style": "IPY_MODEL_205a8acbefb64bf5ab23e55fb55f1fa9",
            "value": "Epoch 0:  26%"
          }
        },
        "92c90646fd5f4294ad860bac64ef2695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d27f53055084a58a460af6abc5df95e",
            "max": 3200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f9cb8bf6fe74c4fa757dedc9947d769",
            "value": 840
          }
        },
        "a82550e9015f4ba1a655cd8a865aac70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dafcfad4242848f2932aeecfe1345026",
            "placeholder": "​",
            "style": "IPY_MODEL_eeedf120d536423ea4b9af4879a63685",
            "value": " 840/3200 [10:55&lt;30:41,  1.28it/s, v_num=3]"
          }
        },
        "d50dd100a48e483cb152fe37957456c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "99f700ce24c44bf68b786bb8bd38d367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "205a8acbefb64bf5ab23e55fb55f1fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d27f53055084a58a460af6abc5df95e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f9cb8bf6fe74c4fa757dedc9947d769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dafcfad4242848f2932aeecfe1345026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeedf120d536423ea4b9af4879a63685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFpwG-G4Exy1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jsDALniQnzj"
      },
      "source": [
        "# Installing Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0yIjToZfKkz",
        "outputId": "9e178cfc-578a-4add-b56b-ee4c2b71294d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.7/201.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.0.2-py3-none-any.whl (719 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.5.0)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.0.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.65.0)\n",
            "Collecting lightning-utilities>=0.7.0\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.4.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.22.4)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (3.25.2)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (23.1.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch_lightning) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch_lightning) (1.3.0)\n",
            "Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch_lightning\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 lightning-utilities-0.8.0 multidict-6.0.4 pytorch_lightning-2.0.2 torchmetrics-0.11.4 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb -qU\n",
        "!pip install pytorch_lightning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g73kDqplmER-"
      },
      "source": [
        "# Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D6qxfMzgEb1",
        "outputId": "ebef3e53-dd0f-4047-b8d7-81f7e928ea88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am7fPcNHQvKJ"
      },
      "source": [
        "# Importing Modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rq2lHM9cPsy1"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import torch \n",
        "import pytorch_lightning as pl\n",
        "import torch.nn as nn\n",
        "from torch.nn  import functional\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import random\n",
        "import csv\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIL_C-NXQ0Mz"
      },
      "source": [
        "# Unzip data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybVd9PVufOhI"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/dl/aksharantar_sampled.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxdJSVilWcQC"
      },
      "source": [
        "# Connecting Wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1MtE97XVbTJV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# wandb.login(key=\"8d6c17aa48af2229c26cbc16513ef266358c0b96\")\n",
        "# wandb.init(project=\"Assignment-02\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hhOmSKoWwCF"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "adHl-oBeKkZA"
      },
      "outputs": [],
      "source": [
        "base_dir = \"aksharantar_sampled/mal/\"\n",
        "\n",
        "train_file = base_dir+\"mal_train.csv\"\n",
        "val_file = base_dir+\"mal_train.csv\"\n",
        "test_file = base_dir+\"mal_train.csv\"\n",
        "\n",
        "train_data = pd.read_csv(train_file,header=None)\n",
        "val_data = pd.read_csv(val_file,header=None)\n",
        "test_data = pd.read_csv(test_file,header=None)\n",
        "\n",
        "\n",
        "\n",
        "latin_chars = {'<PAD>': 0, '<UNK>': 1,'<start>':2,'<end>':3}\n",
        "lang_chars = {'<PAD>': 0, '<UNK>': 1,'<start>':2,'<end>':3}\n",
        "for word in train_data[0]:\n",
        "  for char in word :\n",
        "    if char not in latin_chars:\n",
        "      latin_chars[char] = len(latin_chars)\n",
        "\n",
        "for word in train_data[1]:\n",
        "  for char in word :\n",
        "    if char not in lang_chars:\n",
        "      lang_chars[char] = len(lang_chars)\n",
        "\n",
        "\n",
        "latin_max_length = len(max(train_data[0],key = len))\n",
        "lang_max_length = len(max(train_data[1],key = len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xRcCWNWOUz_e"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def word_to_vec(data):\n",
        "  data1= data.T\n",
        "  data_pairs = []\n",
        "  for i in range(0,len(data)):\n",
        "    word =  [2]+[latin_chars.get(char,latin_chars['<UNK>']) for char in data1[i][0]] + [0]*(latin_max_length - len(data1[i][0]))+[3]\n",
        "    latin_tensor = torch.tensor(word).to(device)\n",
        "    word =  [2]+[lang_chars.get(char,lang_chars['<UNK>']) for char in data1[i][1]] + [0]*(lang_max_length - len(data1[i][1]))+[3]\n",
        "    lang_tensor = torch.tensor(word).to(device)\n",
        "    data_pairs.append([latin_tensor,lang_tensor])\n",
        "  return data_pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "RG4p0iZ9w-Su"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3ArcLs1ASyX4"
      },
      "outputs": [],
      "source": [
        "train_data_pairs = word_to_vec(train_data)\n",
        "val_data_pairs = word_to_vec(val_data)\n",
        "test_data_pairs = word_to_vec(test_data)\n",
        "\n",
        "train_dataloader = DataLoader(train_data_pairs, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data_pairs, batch_size=16, shuffle=False)\n",
        "test_dataloader = DataLoader(test_data_pairs, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngYIl98ThLAR"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WwFilDT7cD0f"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_size,embedding_size,hidden_size,layers,cell_type,bidirectional,dropout):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.cell_type = cell_type\n",
        "    self.embedding = nn.Embedding(input_size,embedding_size)\n",
        "    self.rnn = cell_type(embedding_size,hidden_size,layers,bidirectional = bidirectional,dropout=dropout)\n",
        "\n",
        "  def forward(self,x):\n",
        "    embedding = self.embedding(x)\n",
        "    output,hidden = self.rnn(embedding)\n",
        "\n",
        "    return hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImCSvZjihPRX"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WVF4Sr3DhRav"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,output_size,embedding_size,hidden_size,layers,cell_type,bidirectional,dropout):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.cell_type = cell_type\n",
        "    self.embedding = nn.Embedding(output_size,embedding_size) \n",
        "    self.rnn = cell_type(embedding_size,hidden_size,layers,bidirectional = bidirectional,dropout=dropout)\n",
        "    if bidirectional:\n",
        "      self.out = nn.Linear(hidden_size*2,output_size) \n",
        "    else :\n",
        "      self.out = nn.Linear(hidden_size,output_size) \n",
        "\n",
        "    \n",
        "  def forward(self,x,hidden):\n",
        "    x = x.unsqueeze(1).transpose(0,1)\n",
        "    embedding = self.embedding(x)\n",
        "    output,hidden = self.rnn(embedding,hidden)\n",
        "    output = self.out(output.squeeze(0))\n",
        "\n",
        "    return output,hidden\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTnyND8YhSJ1"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KJdM1Vn1hUWw"
      },
      "outputs": [],
      "source": [
        "import heapq as hq\n",
        "\n",
        "class seq2seq(pl.LightningModule):\n",
        "  def __init__(self,input_size,output_size,embedding_size,hidden_size,encoder_layer_size,decoder_layer_size,cell_type,beam_width,dropout,bidirectional,learning_rate=0.0001):\n",
        "    super(seq2seq,self).__init__()\n",
        "    self.output_size = output_size\n",
        "    self.cell_type = cell_type\n",
        "    self.train_step_acc = []\n",
        "    self.train_step_loss = []\n",
        "    self.val_step_acc = []\n",
        "    self.val_step_loss = []\n",
        "    self.decoder_layer_size = decoder_layer_size #*  2 if bidirectional else 1\n",
        "    self.bidirectional = bidirectional\n",
        "    self.encoder_layer_size = encoder_layer_size \n",
        "    self.beam_width = beam_width\n",
        "    self.encoder = Encoder(input_size,embedding_size,hidden_size,encoder_layer_size,cell_type,bidirectional,dropout)\n",
        "    self.decoder = Decoder(output_size,embedding_size,hidden_size,decoder_layer_size,cell_type,bidirectional,dropout)\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "  def beam_search(self,hidden,input,beam_width,output_len,output_seq):\n",
        "    queue = []\n",
        "    queue.append((input,1,hidden))\n",
        "    for t in range(output_len):\n",
        "      queue_temp = []\n",
        "      for i in range(len(queue)):\n",
        "        (input,prob_parent,hidden) = queue[i]\n",
        "        output_rnn,hidden = self.decoder( input ,hidden)\n",
        "        prob , index = torch.topk(output_rnn,beam_width)\n",
        "        output_rnn = output_rnn.squeeze(1)\n",
        "        for j in range(beam_width):\n",
        "          prob_score = prob_parent*prob[0][j]\n",
        "          queue_temp.append((torch.tensor([index[0][j]]).to(device),prob_score,hidden))\n",
        "      output_seq[t] = output_rnn\n",
        "      hq.heapify(queue_temp)\n",
        "      queue = queue_temp[:beam_width]\n",
        "    return  output_seq\n",
        "\n",
        "  def forward(self,input,output,tf = 1) :\n",
        "    output_len = output.shape[1]\n",
        "    batch_size = input.shape[0]\n",
        "    output_size = self.output_size\n",
        "    hidden = self.encoder(input.transpose(0,1))\n",
        "    if self.encoder_layer_size > self.decoder_layer_size :\n",
        "      hidden = hidden[-1*self.decoder_layer_size*  2 if self.bidirectional else 1:]\n",
        "    elif self.encoder_layer_size < self.decoder_layer_size :\n",
        "      for i in range(self.decoder_layer_size - self.encoder_layer_size):\n",
        "        temp_hidden = hidden[-1 *2 if self.bidirectional else 1:]\n",
        "        if(temp_hidden.shape[0] == 0) :\n",
        "          temp_hidden = hidden\n",
        "\n",
        "        hidden = torch.cat((hidden,temp_hidden) )\n",
        "    output_seq = torch.zeros(output.shape[0],batch_size,output_size).to(device)\n",
        "\n",
        "\n",
        "    output = output.transpose(0,1)\n",
        "    next_input = output[:,0]\n",
        "    if self.beam_width == 1:\n",
        "      for t in range(output.shape[1]):\n",
        "        output_rnn,hidden = self.decoder( next_input ,hidden)\n",
        "        output_seq[t] = output_rnn.squeeze(1)\n",
        "        next_input =  output_seq[t].argmax(1) if random.random() < tf else output[:,t]\n",
        "      return output_seq\n",
        "    else :\n",
        "      # print(output.shape[0])\n",
        "      # output_seq_temp = torch.zeros(output.shape[0],1,output_size).to(device)\n",
        "      # output_seq_temp = self.beam_search(hidden,next_input,self.beam_width,output.shape[1],output_seq)\n",
        "      # output_seq = output_seq_temp\n",
        "\n",
        "      for i in range(batch_size):\n",
        "        output_seq_temp = torch.zeros(output.shape[1],1,output_size).to(device)\n",
        "        # print(hidden.shape,next_input.shape,batch_size)\n",
        "        # print(hidden[:,i,:]..shape)\n",
        "        output_seq_temp = self.beam_search(hidden[:,i:i+1,:],next_input[i:i+1],self.beam_width,output.shape[1],output_seq_temp)\n",
        "        output_seq[:,i:i+1,:] = output_seq_temp\n",
        "      return output_seq\n",
        "\n",
        "\n",
        "  def training_step(self,batch):\n",
        "    input,output = batch\n",
        "\n",
        "    output = output.permute(1,0)\n",
        "    output_seq = self(input,output)\n",
        "    output = output.permute(1,0)\n",
        "\n",
        "    output_seq_2 = torch.zeros(output_seq.shape).to(device)\n",
        "    batch_n = np.arange(len(output_seq))\n",
        "\n",
        "    for f in range(len(output)):\n",
        "      col = output[f]\n",
        "      output_seq_2[batch_n,f,np.array(col.cpu())] = 1\n",
        "    output_dim = output_seq.shape[-1]\n",
        "    output_seq_t1 = output_seq[1:].view(-1,output_dim)\n",
        "    output_seq_t2 = output_seq_2[1:].view(-1,output_dim)\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    loss = loss(output_seq_t1,output_seq_t2).mean()\n",
        "    \n",
        "    output = output.permute(1,0)\n",
        "    output_ = torch.argmax(output_seq,2)\n",
        "    acc_1 = torch.all(output_[1:-1,:] == output[1:-1,:],dim=0)\n",
        "    acc = torch.sum(acc_1 == True)/len(acc_1)\n",
        "\n",
        "    self.log('train_loss', loss,on_epoch = True,on_step = False,prog_bar=True)\n",
        "    self.train_step_loss.append(loss)\n",
        "    self.log('train_acc', acc,on_epoch = True,on_step = False,prog_bar=True)\n",
        "    self.train_step_acc.append(acc)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "  def on_train_epoch_end(self):\n",
        "    \n",
        "    train_acc =  torch.stack(self.train_step_acc).mean()\n",
        "    train_loss =  torch.stack(self.train_step_loss).mean()\n",
        "    val_acc =  torch.stack(self.val_step_acc).mean()\n",
        "    val_loss =  torch.stack(self.val_step_loss).mean()\n",
        "    # print(\"train_loss:\",train_loss.item(),\"train_acc\",train_acc.item(),\"val_loss:\",val_loss.item(),\"val_acc\",val_acc.item())\n",
        "    wandb.log({\"train_loss\":train_loss.item(),\"train_acc\":train_acc.item(),\"val_loss\":val_loss.item(),\"val_acc\":val_acc.item()})\n",
        "    self.train_step_acc.clear() \n",
        "    self.train_step_loss.clear() \n",
        "    self.val_step_acc.clear() \n",
        "    self.val_step_loss.clear() \n",
        "\n",
        "\n",
        "  def validation_step(self, batch,batch_idx):\n",
        "    input,output = batch\n",
        "\n",
        "    output = output.permute(1,0)\n",
        "    output_seq = self(input,output,0)\n",
        "    output = output.permute(1,0)\n",
        "\n",
        "    output_seq_2 = torch.zeros(output_seq.shape).to(device)\n",
        "    batch_n = np.arange(len(output_seq))\n",
        "\n",
        "    for f in range(len(output)):\n",
        "      col = output[f]\n",
        "      output_seq_2[batch_n,f,np.array(col.cpu())] = 1\n",
        "\n",
        "    output_dim = output_seq.shape[-1]\n",
        "  \n",
        "    output_seq_t1 = output_seq[1:].view(-1,output_dim)\n",
        "    output_seq_t2 = output_seq_2[1:].view(-1,output_dim)\n",
        "\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    loss = loss(output_seq_t1,output_seq_t2).mean()\n",
        "    output = output.permute(1,0)\n",
        "    output_ = torch.argmax(output_seq,2)\n",
        "    acc_1 = torch.all(output_[1:-1,:] == output[1:-1,:],dim=0)\n",
        "    acc = torch.sum(acc_1 == True)/len(acc_1)\n",
        "\n",
        "    self.log('val_loss', loss,on_epoch = True,on_step = False,prog_bar=True)\n",
        "    self.val_step_loss.append(loss)\n",
        "    self.log('val_acc', acc,on_epoch = True,on_step = False,prog_bar=True)\n",
        "    self.val_step_acc.append(acc)\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return torch.optim.Adam(self.parameters(),lr= self.learning_rate)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG9TRpW9n1yp"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = seq2seq(input_size = len(latin_chars), output_size = len(lang_chars),\n",
        "                embedding_size = 32, hidden_size = 16,encoder_layer_size = 1,\n",
        "                decoder_layer_size = 1,cell_type = nn.GRU,\n",
        "                beam_width = 2,dropout= 0.2,\n",
        "                bidirectional =False ,learning_rate = 0.001)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(max_epochs = 30)\n",
        "trainer.fit(model, train_dataloader,val_dataloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317,
          "referenced_widgets": [
            "ee3090c4db6847fe93a9e85db6592a00",
            "f6a73b5be0334b8fbec17a336b1c537b",
            "a91821799b3e4b8fbb0e68ca25fd010b",
            "7661278b6b884818b77f7e01b27332f1",
            "9e753b81d7204a12bf4fa5534c67d241",
            "76e88cfc66cc44fbb47f1e4f3e447742",
            "7ae4462e26c0427182cb25542b2b404b",
            "031aa630dd154c8cb5b72f4d8d9422a0",
            "187b1cc830bf4072893d97071b388291",
            "5a57123e6af246de8744e8944715acff",
            "e210af776b11499cb624cd8d62307488",
            "9b5f2c2b977c41bc8ed0cfa5654766f4",
            "3034ff8d2536450b993967151cb793cd",
            "92c90646fd5f4294ad860bac64ef2695",
            "a82550e9015f4ba1a655cd8a865aac70",
            "d50dd100a48e483cb152fe37957456c6",
            "99f700ce24c44bf68b786bb8bd38d367",
            "205a8acbefb64bf5ab23e55fb55f1fa9",
            "8d27f53055084a58a460af6abc5df95e",
            "5f9cb8bf6fe74c4fa757dedc9947d769",
            "dafcfad4242848f2932aeecfe1345026",
            "eeedf120d536423ea4b9af4879a63685"
          ]
        },
        "id": "6UWfslDVgKjE",
        "outputId": "d0abe2c1-4732-402b-b70d-3ed39cd9d853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name    | Type    | Params\n",
            "------------------------------------\n",
            "0 | encoder | Encoder | 3.4 K \n",
            "1 | decoder | Decoder | 6.0 K \n",
            "------------------------------------\n",
            "9.3 K     Trainable params\n",
            "0         Non-trainable params\n",
            "9.3 K     Total params\n",
            "0.037     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee3090c4db6847fe93a9e85db6592a00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b5f2c2b977c41bc8ed0cfa5654766f4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFlfk8HZm2Ma"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGn-q7HuYuho"
      },
      "source": [
        "\n",
        "# Sweep Config"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cn7BwfMtkFhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsX9MeVTEli8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "config= {\n",
        "    'method': 'bayes',\n",
        "    'name': 'sweep',\n",
        "    'metric': {\n",
        "        'goal': 'maximize', \n",
        "        'name': 'val_acc'\n",
        "      },\n",
        "    \"parameters\":\n",
        "    {\n",
        "      \n",
        "    \"bidirectional\" :{\n",
        "        \"values\" : [True,False]\n",
        "    },\n",
        "    \"dropout\" :{\n",
        "        \"values\" : [0,0.2,0.3]\n",
        "    },\n",
        "    \"cell_type\" :{\n",
        "          \"values\" : [\"RNN\", \"GRU\", \"LSTM\"]\n",
        "    },\n",
        "      \"epochs\" :{\n",
        "          \"values\" : [10,  15, 20]\n",
        "    },\n",
        "     \n",
        "      \"encoder_layers\" :{\n",
        "          \"values\" : [1,  2, 3]\n",
        "    },\n",
        "      \"decoder_layers\" :{\n",
        "          \"values\" : [1,  2, 3]\n",
        "    },\n",
        "      \"embedding_size\" :{\n",
        "          \"values\" : [16,32,64,256]\n",
        "    },\n",
        "      \"hidden_layer_size\" :{\n",
        "          \"values\" : [16,32,64,256]\n",
        "    },\n",
        "\n",
        "      \"learning_rate\" :{\n",
        "          \"values\" : [1e-3,1e-4]\n",
        "    }\n",
        "\n",
        "    }\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PbMUSStY4rm"
      },
      "source": [
        "# Sweep Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLgcFoCIFOh1"
      },
      "outputs": [],
      "source": [
        "\n",
        "cell_map = {\"RNN\":nn.RNN, \"GRU\":nn.GRU, \"LSTM\":nn.LSTM}\n",
        "def sweeprun():\n",
        "\n",
        "  wandb.init()\n",
        "  bidirectional = wandb.config.bidirectional\n",
        "  dropout = wandb.config.dropout\n",
        "  cell_type = wandb.config.cell_type\n",
        "\n",
        "  encoder_layers = wandb.config.encoder_layers\n",
        "  decoder_layers = wandb.config.decoder_layers\n",
        "  epochs = wandb.config.epochs\n",
        "  learning_rate = wandb.config.learning_rate\n",
        "\n",
        "  embedding_size = wandb.config.embedding_size\n",
        "  hidden_layer_size = wandb.config.hidden_layer_size\n",
        "\n",
        "  run_name = \"lr_{}_rnn_{}_dp_{}_bd_{}_el_{}_dl_{}_ep_{}_es_{}_hs_{}\".format(learning_rate,cell_type, dropout, bidirectional,encoder_layers, decoder_layers,epochs,embedding_size,hidden_layer_size)\n",
        "\n",
        "  cell_type = cell_map[cell_type]\n",
        "  model = seq2seq(input_size = len(latin_chars), output_size = len(lang_chars),\n",
        "                embedding_size = embedding_size, hidden_size = hidden_layer_size,encoder_layer_size = encoder_layers,\n",
        "                decoder_layer_size = decoder_layers,cell_type = nn.GRU,dropout= dropout,\n",
        "                bidirectional =bidirectional ,learning_rate = learning_rate)\n",
        "  model.to(device)\n",
        "\n",
        "  trainer = pl.Trainer(max_epochs=epochs,accelerator = 'gpu') \n",
        "  trainer.fit(model, train_dataloader,val_dataloader)\n",
        "\n",
        "  wandb.run.name = run_name\n",
        "  wandb.finish()\n",
        "\n",
        "\n",
        "\n",
        "sweep_id = wandb.sweep(config,project=\"Assignment-03\", entity = \"saisreeram\")\n",
        "wandb.agent(sweep_id, sweeprun)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBdpvef8wfZj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bx0a4kiIESG0"
      },
      "outputs": [],
      "source": [
        "a = [1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJdI4qoN_jtz"
      },
      "outputs": [],
      "source": [
        "a[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB_9g3pq_n5s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28l3kvlkACjj"
      },
      "outputs": [],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oj7lzSmJJx6r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}